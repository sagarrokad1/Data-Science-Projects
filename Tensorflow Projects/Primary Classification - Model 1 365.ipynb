{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function NpzFile.__del__ at 0x0000020E29A353A8>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\.conda\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\npyio.py\", line 230, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\admin\\.conda\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\npyio.py\", line 221, in close\n",
      "    if self.zip is not None:\n",
      "AttributeError: 'NpzFile' object has no attribute 'zip'\n"
     ]
    }
   ],
   "source": [
    "data_train=np.load(r'C:\\Users\\admin\\Downloads\\Primary categories - Train.npz')\n",
    "data_val=np.load(r'C:\\Users\\admin\\Downloads\\Primary categories - Validation.npz')\n",
    "data_test=np.load(r'C:\\Users\\admin\\Downloads\\Primary categories - Test.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train=data_train['images']\n",
    "labels_train=data_train['labels']\n",
    "\n",
    "images_val=data_val['images']\n",
    "labels_val=data_val['labels']\n",
    "\n",
    "images_test=data_test['images']\n",
    "labels_test=data_test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train=images_train/255.0\n",
    "images_val=images_val/255.0\n",
    "images_test=images_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs=15\n",
    "Batch_size=64\n",
    "\n",
    "HP_Filter_Size=hp.HParam('filter_size',hp.Discrete([3,5,7]))\n",
    "HP_Filter_Num=hp.HParam('filter_number',hp.Discrete([32,64,96,128]))\n",
    "\n",
    "METRIC_ACCURACY='accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer(r'Logs/Model 1/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "    hparams=[HP_Filter_Size,HP_Filter_Num],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY,display_name='Accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams,session_num):\n",
    "    model=tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(hparams[HP_Filter_Num],hparams[HP_Filter_Size],activation='relu',input_shape=(120,90,3)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Conv2D(hparams[HP_Filter_Num],3,activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(3)])\n",
    "    loss_rn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(optimizer='adam',loss=loss_rn,metrics=['accuracy'])\n",
    "    log_dir='Logs\\\\Model 1\\\\fit\\\\'+\"run-{}\".format(session_num)\n",
    "    \n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    "        figure = plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        return figure\n",
    "    \n",
    "    def plot_to_image(figure):\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        plt.close(figure)\n",
    "        buf.seek(0)\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        return image\n",
    "    \n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "\n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        test_pred_raw = model.predict(images_val)\n",
    "        test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "        cm = sklearn.metrics.confusion_matrix(labels_val, test_pred)\n",
    "        figure = plot_confusion_matrix(cm, class_names=['Glasses/Sunglasses','Trousers/Jeans','Shoes'])\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "            \n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "    tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1,profile_batch=0)\n",
    "    \n",
    "    early_stopping=tf.keras.callbacks.EarlyStopping(monitor='val_loss',mode='auto',min_delta=0,verbose=0,patience=2,restore_best_weights=True)\n",
    "    model.fit(images_train,labels_train,epochs=Epochs,batch_size=Batch_size,callbacks=[early_stopping,tensorboard_callback,cm_callback],validation_data=(images_val,labels_val),verbose=2)\n",
    "    _,accuracy=model.evaluate(images_val,labels_val)\n",
    "    \n",
    "    model.save(r'saved_models\\Model 1\\Run-{}'.format(session_num))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(log_dir,hparams,session_num):\n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        accuracy=train_test_model(hparams,session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY,accuracy,step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-1\n",
      "{'filter_size': 3, 'filter_number': 32}\n",
      "Train on 12963 samples, validate on 1620 samples\n",
      "Epoch 1/15\n",
      "12963/12963 - 467s - loss: 0.0711 - accuracy: 0.9794 - val_loss: 0.0056 - val_accuracy: 0.9994\n",
      "Epoch 2/15\n",
      "12963/12963 - 680s - loss: 0.0128 - accuracy: 0.9980 - val_loss: 0.0031 - val_accuracy: 0.9994\n",
      "Epoch 3/15\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session_num=1\n",
    "for filter_size in HP_Filter_Size.domain.values:\n",
    "    for filter_num in HP_Filter_Num.domain.values:\n",
    "        hparams={\n",
    "            HP_Filter_Size:filter_size,\n",
    "            HP_Filter_Num:filter_num\n",
    "        }\n",
    "        run_name='run-%d' % session_num\n",
    "        print('---Starting trial: %s' % run_name)\n",
    "        print({h.name:hparams[h] for h in hparams})\n",
    "        run('Logs/Model 1/hparam_tuning/'+run_name,hparams,session_num)\n",
    "        \n",
    "        session_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"Logs/Model 1/hparam_tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'Logs/Model 1/fit'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
